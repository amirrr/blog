---
title: "Are LLMs Good at Detecting Common Sense"
date: 2023-10-10T21:48:12+02:00
draft: true
description: "How good are large language models at assessing whether an statement is common sense or not."
tags: ["common sense", "large language models", "transformers"]
categories: ["research", "nlp", "transformers"]
---

## Are LLMs Good at Detecting Common Sense?

In a world where large language models (LLMs) like GPT-3 and its successors are becoming increasingly integrated into our daily lives, one of the burning questions is: How good are these models at assessing whether a statement reflects common sense or not? Common sense is a fundamental aspect of human intelligence, and it plays a critical role in natural language understanding and communication. So, can LLMs really grasp the nuances of common sense?
The Challenge of Common Sense

Common sense is often defined as the innate, shared understanding of everyday knowledge that most people possess. It encompasses a vast array of facts, assumptions, and contextual information that humans use to make sense of the world. Detecting common sense requires not only a comprehensive understanding of language but also the ability to reason and infer based on background knowledge.


### LLMs and Common Sense

LLMs, such as those based on the transformer architecture, have demonstrated remarkable abilities in various natural language processing (NLP) tasks, including language translation, sentiment analysis, and even generating human-like text. However, when it comes to common sense, the performance of these models is more nuanced.

```text
    Strengths:
        LLMs have access to an enormous amount of text from the internet, which helps them capture a wide range of factual information.
        They can generate text that sounds plausible, which can sometimes pass as common sense.

    Limitations:
        LLMs often lack true understanding; they rely on statistical patterns in the data rather than genuine comprehension.
        They can produce incorrect or nonsensical answers that may appear plausible at first glance.
        These models can be sensitive to input phrasing and may provide different responses to slight rephrasing of the same question.
```


<br>

### The Common Sense Benchmark

To evaluate the common sense abilities of LLMs, researchers have developed benchmark datasets and tasks. These tests challenge models to provide commonsensical responses to various questions and scenarios. While LLMs perform reasonably well on some aspects of these benchmarks, they still struggle with more complex forms of common sense reasoning.
The Road Ahead

The question of whether LLMs are good at detecting common sense is a complex one. While they have made significant strides in natural language understanding, they are far from achieving human-level common sense reasoning. Continued research in the field of NLP and transformer-based models is essential to improve their common sense abilities.

In conclusion, while LLMs have demonstrated impressive language capabilities, they are not infallible when it comes to common sense. Their performance varies depending on the specific task and the complexity of the common sense reasoning required. As these models continue to evolve, researchers and developers will need to address these limitations to ensure that they can truly understand and apply common sense in a more reliable manner.